import urllib.request
import urllib.parse
import urllib.error
from bs4 import BeautifulSoup
import time
import re

pokedex = ['Bulbasaur',
           'Ivysaur',
           'Venusaur',
           'Charmander',
           'Charmeleon',
           'Charizard',
           'Squirtle',
           'Wartortle',
           'Blastoise',
           'Caterpie',
           'Metapod',
           'Butterfree',
           'Weedle',
           'Kakuna',
           'Beedrill',
           'Pidgey',
           'Pidgeotto',
           'Pidgeot',
           'Rattata',
           'Raticate',
           'Spearow',
           'Fearow',
           'Ekans',
           'Arbok',
           'Pikachu',
           'Raichu',
           'Sandshrew',
           'Sandslash',
           'Nidoran♀',
           'Nidorina',
           'Nidoqueen',
           'Nidoran♂',
           'Nidorino',
           'Nidoking',
           'Clefairy',
           'Clefable',
           'Vulpix',
           'Ninetales',
           'Jigglypuff',
           'Wigglytuff',
           'Zubat',
           'Golbat',
           'Oddish',
           'Gloom',
           'Vileplume',
           'Paras',
           'Parasect',
           'Venonat',
           'Venomoth',
           'Diglett',
           'Dugtrio',
           'Meowth',
           'Persian',
           'Psyduck',
           'Golduck',
           'Mankey',
           'Primeape',
           'Growlithe',
           'Arcanine',
           'Poliwag',
           'Poliwhirl',
           'Poliwrath',
           'Abra',
           'Kadabra',
           'Alakazam',
           'Machop',
           'Machoke',
           'Machamp',
           'Bellsprout',
           'Weepinbell',
           'Victreebel',
           'Tentacool',
           'Tentacruel',
           'Geodude',
           'Graveler',
           'Golem',
           'Ponyta',
           'Rapidash',
           'Slowpoke',
           'Slowbro',
           'Magnemite',
           'Magneton',
           "Farfetch'd",
           'Doduo',
           'Dodrio',
           'Seel',
           'Dewgong',
           'Grimer',
           'Muk',
           'Shellder',
           'Cloyster',
           'Gastly',
           'Haunter',
           'Gengar',
           'Onix',
           'Drowzee',
           'Hypno',
           'Krabby',
           'Kingler',
           'Voltorb',
           'Electrode',
           'Exeggcute',
           'Exeggutor',
           'Cubone',
           'Marowak',
           'Hitmonlee',
           'Hitmonchan',
           'Lickitung',
           'Koffing',
           'Weezing',
           'Rhyhorn',
           'Rhydon',
           'Chansey',
           'Tangela',
           'Kangaskhan',
           'Horsea',
           'Seadra',
           'Goldeen',
           'Seaking',
           'Staryu',
           'Starmie',
           'Mr. Mime',
           'Scyther',
           'Jynx',
           'Electabuzz',
           'Magmar',
           'Pinsir',
           'Tauros',
           'Magikarp',
           'Gyarados',
           'Lapras',
           'Ditto',
           'Eevee',
           'Vaporeon',
           'Jolteon',
           'Flareon',
           'Porygon',
           'Omanyte',
           'Omastar',
           'Kabuto',
           'Kabutops',
           'Aerodactyl',
           'Snorlax',
           'Articuno',
           'Zapdos',
           'Moltres',
           'Dratini',
           'Dragonair',
           'Dragonite',
           'Mewtwo',
           'Mew']
hms = ["Fly",
       "Surf",
       "Strength",
       "Cut",
       "Flash"]

url1 = r"https://bulbapedia.bulbagarden.net/wiki/"
url2 = r"_(Pokémon)/Generation_I_learnset#By_leveling_up"
final_url = []

for pokemon in pokedex:
    throw = pokemon + url2
    appendable = url1 + throw
    print(appendable)
    appendable = appendable.encode('utf-8')
    final_url.append(appendable)

for url in final_url:
    count = 0
    print(url)
    html = urllib.request.urlopen(url).read()
    soup = BeautifulSoup(html, 'html.parser')
    for tag in soup.find_all('table'):
        if count < 2:
            print(tag.text)
            count += 1
